# Data transformation


```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width = 300)
```


```{r, message=FALSE}
library(readxl)
library(tidyverse)
library(ggplot2)
library(stringr)
library(ggpubr)
```


## Read data

Our data is come from *Open Door*, which is sponsored by the U.S. Government and Institute of International Education. The original data file format is Microsoft Excel, and `NA` is represent by "-". More, the first column name of place code is empty, so we name it by `Code of Origin`.

<br>

```{r}
projdata <- read_excel("Census_All-Places-of-Origin_OD21.xlsx", 
                       col_types = c("numeric", "text", "numeric", 
                                     "numeric", "numeric", "numeric", "numeric", 
                                     "numeric", "numeric", "numeric", "numeric", "numeric", 
                                     "numeric", "numeric", "numeric", "numeric", "numeric", 
                                     "numeric", "numeric", "numeric", "numeric", "numeric", 
                                     "numeric", "numeric", "numeric", "numeric", "numeric", 
                                     "numeric", "numeric", "numeric", "numeric", "numeric", 
                                     "numeric", "numeric"),
                       na = "-",
                       col_names = T)
names(projdata)[1] <- "Code of Origin"
projdata <- projdata %>%
  select(`Place of Origin`,`Code of Origin`, `1949/50`:`2020/21`)

knitr::kable(
  head(projdata[, 1:8], 4), booktabs = TRUE,
  caption = 'A table of the first 4 rows of our final project data.'
)
```

<br>

Here we can see the data have meaningless NA row, and the value in `Place of Origin` not unified into one logistic type, for example, all value in side are countries or regions. Thus, we need to cleaning them before analysis.

<br>


## Cleaning

### Remove the empty row and extra notes in data
```{r}
uselessRow <- rowSums(is.na(projdata)) == ncol(projdata)
numNARow <- sum(uselessRow)
numNARow

projdata <- projdata[!uselessRow,] %>%
  filter(!grepl(":",`Place of Origin`))

sum(rowSums(is.na(projdata)) == ncol(projdata))


knitr::kable(
  tail(projdata[, 1:8], 3), booktabs = TRUE,
  caption = 'A table of the last 3 rows to check no extra information.'
)
```

<br>

Here we can see we remove the empty rows and notes in the end. Then we can clean the value.

<br>

### Unified logic type of value and group


In this part, we first remove the grouped summary, then deal with the former country and grouped unspecified. We assign them, based their code, on eight `Continents`, which are: Africa, Asia, Europe, Latin America & Caribbean, Middle East, North America, Oceania and Unknown State.

In addition, we grouped the Unspecified countries/regions to unspecified eight continents to facilitate future analysis.

```{r}

projdata.re.state <- projdata %>%
  filter(!grepl("[0-9][0-9]00", `Code of Origin`)) %>%
  filter(!grepl("[A-Z]+$", `Place of Origin`)) %>% 
  mutate(Continents = case_when(substring(`Code of Origin`, 1, 1) == 1 ~ "Africa",
                                substring(`Code of Origin`, 1, 1) == 2 ~ "Asia",
                                substring(`Code of Origin`, 1, 1) == 3 ~ "Europe",
                                substring(`Code of Origin`, 1, 1) == 4 ~ "Latin America & Caribbean",
                                substring(`Code of Origin`, 1, 1) == 5 ~ "Middle East",
                                substring(`Code of Origin`, 1, 1) == 6 ~ "North America",
                                substring(`Code of Origin`, 1, 1) == 7 ~ "Oceania",
                                `Place of Origin` == "Stateless" ~ "Unknown State"
  )
  )

projdata.re.state[projdata.re.state$`Place of Origin` 
                  == "Bermuda",]$Continents <- "Latin America & Caribbean"

temp.data <- projdata.re.state %>%
  filter(grepl("[0-9]999", `Code of Origin`) | is.na(`Code of Origin`))

temp.data.unsp <- temp.data %>%
  filter(grepl("Unspecified",`Place of Origin`) ) %>%
  mutate(Continents = case_when(grepl("Africa",`Place of Origin`) ~ "Africa",
                                grepl("Asia",`Place of Origin`) ~ "Asia",
                                grepl("Europe",`Place of Origin`) ~ "Europe",
                                grepl("Latin America & Caribbean",`Place of Origin`) ~ "Latin America & Caribbean",
                                grepl("South America",`Place of Origin`) ~ "Latin America & Caribbean",
                                grepl("Caribbean",`Place of Origin`) ~ "Latin America & Caribbean",
                                grepl("Mexico",`Place of Origin`) ~ "Latin America & Caribbean",
                                grepl("Middle East",`Place of Origin`) ~ "Middle East",
                                grepl("North America",`Place of Origin`) ~ "North America",
                                grepl("Pacific",`Place of Origin`) ~ "Oceania"
  )
  ) %>%
  group_by(Continents) %>%
  summarize(.,across(where(is.numeric), ~sum(.x, na.rm = T))) %>%
  mutate(`Place of Origin` = paste(Continents, "Unspecified", sep = ", ")) %>%
  select(`Place of Origin`, `Code of Origin`, `1949/50`:`2020/21`, Continents)

temp.data.fna <- temp.data  %>%
  filter(!grepl("Unspecified",`Place of Origin`) ) %>%
  mutate(Continents = case_when(grepl("Former",`Place of Origin`) ~ "Europe",
                                grepl("Serbia",`Place of Origin`) ~ "Europe",
                                grepl("Antilles",`Place of Origin`) ~ "Latin America & Caribbean",
                                grepl("Sahara",`Place of Origin`) ~ "Africa"
  )
  )

```



## Data use for next few parts

We combine the unspecified Continents data to grouped data, and get the final data set we will use for analysis.
```{r}
df <- projdata.re.state %>%
  filter(!grepl("Unspecified",`Place of Origin`) ) %>%
  rows_update(temp.data.fna, by = "Place of Origin") %>%
  rbind(., temp.data.unsp)

knitr::kable(
  head(df[, 1:8], 6), booktabs = TRUE,
  caption = 'A table of the first 6 rows of data ready for use in the future analysis.'
)
```

<br>

In next chapter, we will discuss the missing values of our data.


